{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LABEL\n",
      "ham     4825\n",
      "spam     747\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LABEL</th>\n",
       "      <th>CONTENT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  LABEL                                            CONTENT\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the sms database\n",
    "# the sms database has real emails\n",
    "sms_database = pd.read_csv('SMSSpamCollection', sep='\\t',\n",
    "header=None, names = ['LABEL', 'CONTENT'])\n",
    "\n",
    "# the structure of the database\n",
    "print(sms_database['LABEL'].value_counts())\n",
    "sms_database.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LABEL</th>\n",
       "      <th>CONTENT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>[go, until, jurong, point,, crazy.., available...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>[ok, lar..., joking, wif, u, oni...]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>[free, entry, in, 2, a, wkly, comp, to, win, f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>[u, dun, say, so, early, hor..., u, c, already...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>[nah, i, don't, think, he, goes, to, usf,, he,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  LABEL                                            CONTENT\n",
       "0   ham  [go, until, jurong, point,, crazy.., available...\n",
       "1   ham               [ok, lar..., joking, wif, u, oni...]\n",
       "2  spam  [free, entry, in, 2, a, wkly, comp, to, win, f...\n",
       "3   ham  [u, dun, say, so, early, hor..., u, c, already...\n",
       "4   ham  [nah, i, don't, think, he, goes, to, usf,, he,..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# clean the data\n",
    "# transform all words to lowercase\n",
    "sms_database['CONTENT'] = sms_database['CONTENT'].str.lower()\n",
    "\n",
    "# split per sentence\n",
    "sms_database['CONTENT'] = sms_database['CONTENT'].str.split()\n",
    "\n",
    "sms_database.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train database: (4457, 2)\n",
      "test database: (1115, 2)\n"
     ]
    }
   ],
   "source": [
    "# randomrize the database\n",
    "randomized_database = sms_database.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# calculate the size of train and test database\n",
    "# 80% is train database and 20% is test\n",
    "train_size = int(sms_database.shape[0] * 0.8)\n",
    "\n",
    "# split the database into train_database and test_database\n",
    "train_database = randomized_database[ : train_size]\n",
    "test_database = randomized_database[train_size : ]\n",
    "\n",
    "# the size of train and test database\n",
    "print(f'train database: {train_database.shape}')\n",
    "print(f'test database: {test_database.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are different 11917 words in train database.\n"
     ]
    }
   ],
   "source": [
    "# calculate all the words in the train dataset\n",
    "total_words = []\n",
    "\n",
    "for content in train_database['CONTENT']:\n",
    "    for word in content:\n",
    "        total_words.append(word)\n",
    "\n",
    "# record words without repetition\n",
    "total_words = list(set(total_words))\n",
    "print(f'There are different {len(total_words)} words in train database.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classes</th>\n",
       "      <th>800</th>\n",
       "      <th>1-month</th>\n",
       "      <th>k.i</th>\n",
       "      <th>birds</th>\n",
       "      <th>iknow</th>\n",
       "      <th>germany</th>\n",
       "      <th>asia.</th>\n",
       "      <th>gong.</th>\n",
       "      <th>skye</th>\n",
       "      <th>...</th>\n",
       "      <th>armand</th>\n",
       "      <th>references..</th>\n",
       "      <th>londn</th>\n",
       "      <th>18</th>\n",
       "      <th>price</th>\n",
       "      <th>lac</th>\n",
       "      <th>lunch:)</th>\n",
       "      <th>collages</th>\n",
       "      <th>08448350055</th>\n",
       "      <th>goodnite</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 11917 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   classes  800  1-month  k.i  birds  iknow  germany  asia.  gong.  skye  ...  \\\n",
       "0        0    0        0    0      0      0        0      0      0     0  ...   \n",
       "1        0    0        0    0      0      0        0      0      0     0  ...   \n",
       "2        0    0        0    0      0      0        0      0      0     0  ...   \n",
       "3        0    0        0    0      0      0        0      0      0     0  ...   \n",
       "4        0    0        0    0      0      0        0      0      0     0  ...   \n",
       "\n",
       "   armand  references..  londn  18  price  lac  lunch:)  collages  \\\n",
       "0       0             0      0   0      0    0        0         0   \n",
       "1       0             0      0   0      0    0        0         0   \n",
       "2       0             0      0   0      0    0        0         0   \n",
       "3       0             0      0   0      0    0        0         0   \n",
       "4       0             0      0   0      0    0        0         0   \n",
       "\n",
       "   08448350055  goodnite  \n",
       "0            0         0  \n",
       "1            0         0  \n",
       "2            0         0  \n",
       "3            0         0  \n",
       "4            0         0  \n",
       "\n",
       "[5 rows x 11917 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate the frequency of each word in each email\n",
    "word_freq_per_email = {}\n",
    "row_size = train_database.shape[0]\n",
    "\n",
    "# create a new void dictionary to record the frequency\n",
    "# the size of dictionary = len(total_words) * rows of train_database\n",
    "for word in total_words:\n",
    "    word_freq_per_email[word] = [0] * row_size\n",
    "\n",
    "# calculate the frequency of per word and save in the dictionary\n",
    "for index, content in enumerate(train_database['CONTENT']):\n",
    "    for word in content:\n",
    "        word_freq_per_email[word][index] += 1\n",
    "\n",
    "# transform word_freq from dictionary to dataframe\n",
    "word_freq = pd.DataFrame(word_freq_per_email)\n",
    "word_freq.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LABEL</th>\n",
       "      <th>CONTENT</th>\n",
       "      <th>classes</th>\n",
       "      <th>800</th>\n",
       "      <th>1-month</th>\n",
       "      <th>k.i</th>\n",
       "      <th>birds</th>\n",
       "      <th>iknow</th>\n",
       "      <th>germany</th>\n",
       "      <th>asia.</th>\n",
       "      <th>...</th>\n",
       "      <th>armand</th>\n",
       "      <th>references..</th>\n",
       "      <th>londn</th>\n",
       "      <th>18</th>\n",
       "      <th>price</th>\n",
       "      <th>lac</th>\n",
       "      <th>lunch:)</th>\n",
       "      <th>collages</th>\n",
       "      <th>08448350055</th>\n",
       "      <th>goodnite</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>[squeeeeeze!!, this, is, christmas, hug.., if,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>[and, also, i've, sorta, blown, him, off, a, c...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>[mmm, thats, better, now, i, got, a, roast, do...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>[mm, have, some, kanji, dont, eat, anything, h...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>[so, there's, a, ring, that, comes, with, the,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 11919 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  LABEL                                            CONTENT  classes  800  \\\n",
       "0   ham  [squeeeeeze!!, this, is, christmas, hug.., if,...        0    0   \n",
       "1   ham  [and, also, i've, sorta, blown, him, off, a, c...        0    0   \n",
       "2   ham  [mmm, thats, better, now, i, got, a, roast, do...        0    0   \n",
       "3   ham  [mm, have, some, kanji, dont, eat, anything, h...        0    0   \n",
       "4   ham  [so, there's, a, ring, that, comes, with, the,...        0    0   \n",
       "\n",
       "   1-month  k.i  birds  iknow  germany  asia.  ...  armand  references..  \\\n",
       "0        0    0      0      0        0      0  ...       0             0   \n",
       "1        0    0      0      0        0      0  ...       0             0   \n",
       "2        0    0      0      0        0      0  ...       0             0   \n",
       "3        0    0      0      0        0      0  ...       0             0   \n",
       "4        0    0      0      0        0      0  ...       0             0   \n",
       "\n",
       "   londn  18  price  lac  lunch:)  collages  08448350055  goodnite  \n",
       "0      0   0      0    0        0         0            0         0  \n",
       "1      0   0      0    0        0         0            0         0  \n",
       "2      0   0      0    0        0         0            0         0  \n",
       "3      0   0      0    0        0         0            0         0  \n",
       "4      0   0      0    0        0         0            0         0  \n",
       "\n",
       "[5 rows x 11919 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_freq = pd.concat([train_database, word_freq], axis=1, ignore_index=False)\n",
    "word_freq.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the dataframe accroding to LABEL\n",
    "word_freq_spam = word_freq.groupby('LABEL').get_group('spam')\n",
    "word_freq_ham = word_freq.groupby('LABEL').get_group('ham')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# P(spam) = the number of words in spam / total number of words\n",
    "prob_prior_spam = len(word_freq_spam) / len(word_freq)\n",
    "\n",
    "# P(ham) = the number of words in ham / total number of words\n",
    "prob_prior_ham = len(word_freq_ham) / len(word_freq)\n",
    "\n",
    "# the number of words in spam email\n",
    "number_words_spam = word_freq_spam['CONTENT'].apply(len).sum()\n",
    "\n",
    "# the number of words in ham email\n",
    "number_words_ham = word_freq_ham['CONTENT'].apply(len).sum()\n",
    "\n",
    "# the number of total words\n",
    "number_words = len(total_words)\n",
    "\n",
    "# set the parameter of Laplace smoothing\n",
    "alpha = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_prob_spam = {word : 0 for word in total_words}\n",
    "words_prob_ham = {word : 0 for word in total_words}\n",
    "\n",
    "for word in total_words:\n",
    "    # sum fo frequency of a unique word in spam email\n",
    "    # just like the sum of a column in the dataframe\n",
    "    word_total_freq_spam = word_freq_spam[word].sum()\n",
    "    \n",
    "    # P(word|spam) = the total frequency / total number of words in spam\n",
    "    # Laplace smoothing: P(word|spam) = (the total frequency + 1) / (total number of words in spam + 1 * number of words)\n",
    "    # Laplace is used to avoid P(word|spam) = 0, because there are some frequencies equal to 0\n",
    "    # https://towardsdatascience.com/laplace-smoothing-in-na%C3%AFve-bayes-algorithm-9c237a8bdece\n",
    "    word_prob_spam = (word_total_freq_spam + alpha) / (number_words_spam + alpha * number_words)\n",
    "    words_prob_spam[word] = word_prob_spam\n",
    "\n",
    "    # sum fo frequency of a unique word in ham email\n",
    "    word_total_freq_ham = word_freq_ham[word].sum()\n",
    "\n",
    "    # it is same as the P(word|spam)\n",
    "    word_prob_ham = (word_total_freq_ham + alpha) / (number_words_ham + alpha * number_words)\n",
    "    words_prob_ham[word] = word_prob_ham"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(email):\n",
    "\n",
    "    # accroding to naive bayes, P(spam|word1, word2, ..., wordn) = P(spam) * P(word1|spam) * P(word2|spam) * ... * P(wordn|spam) \n",
    "    prob_spam = prob_prior_spam\n",
    "    prob_ham = prob_prior_ham\n",
    "\n",
    "    for word in email:\n",
    "        if word in total_words:\n",
    "            prob_spam *= words_prob_spam[word]\n",
    "            prob_ham *= words_prob_ham[word]\n",
    "\n",
    "    if prob_spam > prob_ham:\n",
    "        return 'spam'\n",
    "    else:\n",
    "        return 'ham'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_positive = 0\n",
    "true_negtive = 0\n",
    "false_positive = 0\n",
    "false_negtive = 0\n",
    "\n",
    "for label, content in zip(test_database['LABEL'], test_database['CONTENT']):\n",
    "    if classify(content) == label:\n",
    "        if label == 'spam':\n",
    "            true_positive += 1\n",
    "        else:\n",
    "            true_negtive += 1\n",
    "    else:\n",
    "        if label == 'spam':\n",
    "            false_positive += 1\n",
    "        else:\n",
    "            false_negtive += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ture positive: 130\n",
      "ture negtive: 957\n",
      "false positive: 24\n",
      "false negtive: 4\n",
      "accuracy: 0.9748878923766816\n"
     ]
    }
   ],
   "source": [
    "print(f'ture positive: {true_positive}')\n",
    "print(f'ture negtive: {true_negtive}')\n",
    "print(f'false positive: {false_positive}')\n",
    "print(f'false negtive: {false_negtive}')\n",
    "\n",
    "print(f'accuracy: {(true_positive + true_negtive) / (true_positive + true_negtive + false_positive + false_negtive)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
